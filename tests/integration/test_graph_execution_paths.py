"""Comprehensive integration tests for graph execution paths.

This module tests complex graph execution scenarios including interrupts,
command routing, recursion limits, stop requests, and state persistence.
"""

import pytest

from agentflow.checkpointer import InMemoryCheckpointer
from agentflow.exceptions import GraphRecursionError
from agentflow.graph import StateGraph
from agentflow.state import AgentState, ExecutionStatus, Message
from agentflow.utils import Command, END, ResponseGranularity


class TestInterruptExecution:
    """Test interrupt_before and interrupt_after functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        self.checkpointer = InMemoryCheckpointer()
        self.execution_order = []

    def track_node(self, name):
        """Create a node function that tracks execution."""
        def node_func(state: AgentState) -> AgentState:
            self.execution_order.append(name)
            state.context.append(Message.text_message(f"Executed {name}"))
            return state
        return node_func

    @pytest.mark.asyncio
    async def test_interrupt_before_pauses_execution(self):
        """Test that interrupt_before pauses execution before node."""
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", self.track_node("node1"))
        graph.add_node("node2", self.track_node("node2"))
        graph.add_node("node3", self.track_node("node3"))
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")
        graph.add_edge("node2", "node3")
        graph.add_edge("node3", END)
        
        compiled = graph.compile(
            checkpointer=self.checkpointer,
            interrupt_before=["node2"],
        )
        
        # First execution should stop before node2
        result1 = await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": "test_interrupt_before"},
        )
        
        # Should have executed node1 only
        assert "node1" in self.execution_order
        assert "node2" not in self.execution_order
        
        # Resume execution
        self.execution_order.clear()
        result2 = await compiled.ainvoke(
            {},
            {"thread_id": "test_interrupt_before"},
        )
        
        # Should execute node2 and node3
        assert "node2" in self.execution_order
        assert "node3" in self.execution_order

    @pytest.mark.asyncio
    async def test_interrupt_after_pauses_after_node(self):
        """Test that interrupt_after pauses execution after node."""
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", self.track_node("node1"))
        graph.add_node("node2", self.track_node("node2"))
        graph.add_node("node3", self.track_node("node3"))
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")
        graph.add_edge("node2", "node3")
        graph.add_edge("node3", END)
        
        compiled = graph.compile(
            checkpointer=self.checkpointer,
            interrupt_after=["node2"],
        )
        
        # First execution should stop after node2
        result1 = await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": "test_interrupt_after"},
        )
        
        # Should have executed node1 and node2
        assert "node1" in self.execution_order
        assert "node2" in self.execution_order
        assert "node3" not in self.execution_order
        
        # Resume execution
        self.execution_order.clear()
        result2 = await compiled.ainvoke(
            {},
            {"thread_id": "test_interrupt_after"},
        )
        
        # Should execute node3
        assert "node3" in self.execution_order

    @pytest.mark.asyncio
    async def test_multiple_interrupts(self):
        """Test multiple interrupt points in a graph."""
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", self.track_node("node1"))
        graph.add_node("node2", self.track_node("node2"))
        graph.add_node("node3", self.track_node("node3"))
        graph.add_node("node4", self.track_node("node4"))
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")
        graph.add_edge("node2", "node3")
        graph.add_edge("node3", "node4")
        graph.add_edge("node4", END)
        
        compiled = graph.compile(
            checkpointer=self.checkpointer,
            interrupt_after=["node1", "node3"],
        )
        
        thread_id = "test_multiple_interrupts"
        
        # First execution: stops after node1
        await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": thread_id},
        )
        assert self.execution_order == ["node1"]
        
        # Second execution: stops after node3
        self.execution_order.clear()
        await compiled.ainvoke({}, {"thread_id": thread_id})
        assert "node2" in self.execution_order
        assert "node3" in self.execution_order
        assert "node4" not in self.execution_order
        
        # Third execution: completes
        self.execution_order.clear()
        await compiled.ainvoke({}, {"thread_id": thread_id})
        assert "node4" in self.execution_order


class TestCommandAPIRouting:
    """Test Command API for explicit node routing."""

    @pytest.mark.asyncio
    async def test_command_goto_routes_to_node(self):
        """Test that Command.goto routes to specific node."""
        execution_order = []
        
        def node1(state: AgentState) -> Command:
            execution_order.append("node1")
            return Command(goto="node3")
        
        def node2(state: AgentState) -> AgentState:
            execution_order.append("node2")
            return state
        
        def node3(state: AgentState) -> AgentState:
            execution_order.append("node3")
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", node1)
        graph.add_node("node2", node2)
        graph.add_node("node3", node3)
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")  # This should be skipped
        graph.add_edge("node2", END)
        graph.add_edge("node3", END)
        
        compiled = graph.compile()
        
        await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": "test_command_goto"},
        )
        
        # Should execute node1 then node3, skipping node2
        assert execution_order == ["node1", "node3"]

    @pytest.mark.asyncio
    async def test_command_goto_end_terminates(self):
        """Test that Command.goto(END) terminates execution."""
        execution_order = []
        
        def node1(state: AgentState) -> Command:
            execution_order.append("node1")
            return Command(goto=END)
        
        def node2(state: AgentState) -> AgentState:
            execution_order.append("node2")
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", node1)
        graph.add_node("node2", node2)
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")
        graph.add_edge("node2", END)
        
        compiled = graph.compile()
        
        await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": "test_command_end"},
        )
        
        # Should only execute node1
        assert execution_order == ["node1"]

    @pytest.mark.asyncio
    async def test_command_with_state_update(self):
        """Test Command with state updates."""
        def node1(state: AgentState) -> Command:
            new_msg = Message.text_message("From node1", role="assistant")
            return Command(update=new_msg, goto="node2")
        
        def node2(state: AgentState) -> AgentState:
            # Verify we received the message from node1
            assert len(state.context) >= 2  # Initial + from node1
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", node1)
        graph.add_node("node2", node2)
        
        graph.set_entry_point("node1")
        graph.add_edge("node2", END)
        
        compiled = graph.compile()
        
        result = await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": "test_command_update"},
        )
        
        # Verify message was added
        assert len(result["messages"]) >= 1


class TestRecursionLimitEnforcement:
    """Test recursion limit enforcement."""

    @pytest.mark.asyncio
    async def test_recursion_limit_raises_error(self):
        """Test that exceeding recursion limit raises error."""
        call_count = [0]
        
        def infinite_loop(state: AgentState) -> Command:
            call_count[0] += 1
            # Always route back to self
            return Command(goto="loop_node")
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("loop_node", infinite_loop)
        
        graph.set_entry_point("loop_node")
        graph.add_edge("loop_node", "loop_node")
        
        compiled = graph.compile()
        
        with pytest.raises(GraphRecursionError) as exc_info:
            await compiled.ainvoke(
                {"messages": [Message.text_message("Start", role="user")]},
                {"thread_id": "test_recursion", "recursion_limit": 10},
            )
        
        assert "recursion limit" in str(exc_info.value).lower()
        # Should have called exactly up to the limit
        assert call_count[0] >= 10

    @pytest.mark.asyncio
    async def test_custom_recursion_limit(self):
        """Test that custom recursion limit is respected."""
        call_count = [0]
        
        def counting_node(state: AgentState) -> Command:
            call_count[0] += 1
            if call_count[0] < 5:
                return Command(goto="counter")
            return Command(goto=END)
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("counter", counting_node)
        
        graph.set_entry_point("counter")
        
        compiled = graph.compile()
        
        # Should complete successfully with limit > 5
        result = await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": "test_custom_limit", "recursion_limit": 10},
        )
        
        assert call_count[0] == 5


class TestStopRequestHandling:
    """Test stop request handling during execution."""

    @pytest.mark.asyncio
    async def test_stop_request_interrupts_execution(self):
        """Test that stop request interrupts running execution."""
        checkpointer = InMemoryCheckpointer()
        executed_nodes = []
        
        async def slow_node(state: AgentState) -> AgentState:
            executed_nodes.append("slow")
            # Simulate some work
            import asyncio
            await asyncio.sleep(0.1)
            return state
        
        def quick_node(state: AgentState) -> AgentState:
            executed_nodes.append("quick")
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", quick_node)
        graph.add_node("node2", slow_node)
        graph.add_node("node3", quick_node)
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")
        graph.add_edge("node2", "node3")
        graph.add_edge("node3", END)
        
        compiled = graph.compile(checkpointer=checkpointer)
        
        thread_id = "test_stop_request"
        
        # Start execution
        task = compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": thread_id},
        )
        
        # Request stop after a brief delay
        import asyncio
        await asyncio.sleep(0.05)
        await compiled.astop({"thread_id": thread_id})
        
        # Wait for execution to complete (should be interrupted)
        try:
            await task
        except Exception:
            pass  # May raise due to interrupt
        
        # Verify execution was stopped (should not have reached node3)
        # Note: quick_node and slow_node append "quick" and "slow", not node names
        assert "quick" in executed_nodes or "slow" in executed_nodes
        # Due to timing, we can't guarantee exactly which nodes executed


class TestStatePersistenceAndResume:
    """Test state persistence and resume capabilities."""

    @pytest.mark.asyncio
    async def test_state_persists_across_runs(self):
        """Test that state persists across multiple runs."""
        checkpointer = InMemoryCheckpointer()
        
        def increment_node(state: AgentState) -> AgentState:
            # Track count via context_summary
            current_count = int(state.context_summary or "0")
            new_count = current_count + 1
            state.context_summary = str(new_count)
            state.context.append(
                Message.text_message(f"Count: {new_count}", role="assistant")
            )
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("counter", increment_node)
        
        graph.set_entry_point("counter")
        graph.add_edge("counter", END)
        
        compiled = graph.compile(checkpointer=checkpointer)
        
        thread_id = "test_persistence"
        
        # First run
        result1 = await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": thread_id},
        )
        
        # Second run on same thread
        result2 = await compiled.ainvoke(
            {"messages": [Message.text_message("Continue", role="user")]},
            {"thread_id": thread_id},
        )
        
        # State should have persisted
        # Both runs should have added messages
        assert len(result2["messages"]) >= 2

    @pytest.mark.asyncio
    async def test_resume_from_interrupt_preserves_state(self):
        """Test that resuming from interrupt preserves state."""
        checkpointer = InMemoryCheckpointer()
        
        def node1(state: AgentState) -> AgentState:
            # Track execution via context_summary
            state.context_summary = "node1_executed"
            state.context.append(Message.text_message("Node1", role="assistant"))
            return state
        
        def node2(state: AgentState) -> AgentState:
            # Verify state from node1 is present
            assert state.context_summary == "node1_executed"
            state.context.append(Message.text_message("Node2", role="assistant"))
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", node1)
        graph.add_node("node2", node2)
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")
        graph.add_edge("node2", END)
        
        compiled = graph.compile(
            checkpointer=checkpointer,
            interrupt_after=["node1"],
        )
        
        thread_id = "test_resume_state"
        
        # First run: execute node1 and interrupt
        result1 = await compiled.ainvoke(
            {"messages": [Message.text_message("Start", role="user")]},
            {"thread_id": thread_id},
        )
        
        # Second run: resume and execute node2
        result2 = await compiled.ainvoke(
            {},
            {"thread_id": thread_id},
        )
        
        # State should have been preserved
        # Both messages should be present
        assert len(result2["messages"]) >= 2


class TestConditionalEdgesExecution:
    """Test conditional edge routing."""

    @pytest.mark.asyncio
    async def test_conditional_edge_routing(self):
        """Test that conditional edges route correctly."""
        def router(state: AgentState) -> str:
            # Route based on message content
            last_msg = state.context[-1].text() if state.context else ""
            if "high" in last_msg.lower():
                return "high_priority"
            return "low_priority"
        
        executed_path = []
        
        def high_priority_node(state: AgentState) -> AgentState:
            executed_path.append("high")
            return state
        
        def low_priority_node(state: AgentState) -> AgentState:
            executed_path.append("low")
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("router_node", lambda s: s)
        graph.add_node("high_priority", high_priority_node)
        graph.add_node("low_priority", low_priority_node)
        
        graph.set_entry_point("router_node")
        graph.add_conditional_edges(
            "router_node",
            router,
            {
                "high_priority": "high_priority",
                "low_priority": "low_priority",
            },
        )
        graph.add_edge("high_priority", END)
        graph.add_edge("low_priority", END)
        
        compiled = graph.compile()
        
        # Test high priority routing
        result1 = await compiled.ainvoke(
            {"messages": [Message.text_message("High priority task", role="user")]},
            {"thread_id": "test_conditional_1"},
        )
        assert "high" in executed_path
        
        # Test low priority routing
        executed_path.clear()
        result2 = await compiled.ainvoke(
            {"messages": [Message.text_message("Normal task", role="user")]},
            {"thread_id": "test_conditional_2"},
        )
        assert "low" in executed_path


class TestResponseGranularityLevels:
    """Test different response granularity levels."""

    @pytest.mark.asyncio
    async def test_low_granularity_returns_messages_only(self):
        """Test that LOW granularity returns only messages."""
        def simple_node(state: AgentState) -> AgentState:
            state.context.append(Message.text_message("Response", role="assistant"))
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node", simple_node)
        graph.set_entry_point("node")
        graph.add_edge("node", END)
        
        compiled = graph.compile()
        
        result = await compiled.ainvoke(
            {"messages": [Message.text_message("Test", role="user")]},
            {"thread_id": "test_low"},
            response_granularity=ResponseGranularity.LOW,
        )
        
        assert "messages" in result
        assert "state" not in result

    @pytest.mark.asyncio
    async def test_full_granularity_returns_state(self):
        """Test that FULL granularity returns complete state."""
        def simple_node(state: AgentState) -> AgentState:
            state.context.append(Message.text_message("Response", role="assistant"))
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node", simple_node)
        graph.set_entry_point("node")
        graph.add_edge("node", END)
        
        compiled = graph.compile()
        
        result = await compiled.ainvoke(
            {"messages": [Message.text_message("Test", role="user")]},
            {"thread_id": "test_full"},
            response_granularity=ResponseGranularity.FULL,
        )
        
        assert "messages" in result
        assert "state" in result
        assert isinstance(result["state"], AgentState)


class TestStreamingVsNonStreaming:
    """Test streaming and non-streaming execution paths."""

    @pytest.mark.asyncio
    async def test_invoke_and_stream_produce_same_results(self):
        """Test that invoke and stream produce equivalent results."""
        def node1(state: AgentState) -> AgentState:
            state.context.append(Message.text_message("Node1", role="assistant"))
            return state
        
        def node2(state: AgentState) -> AgentState:
            state.context.append(Message.text_message("Node2", role="assistant"))
            return state
        
        graph = StateGraph[AgentState](AgentState())
        graph.add_node("node1", node1)
        graph.add_node("node2", node2)
        
        graph.set_entry_point("node1")
        graph.add_edge("node1", "node2")
        graph.add_edge("node2", END)
        
        compiled = graph.compile()
        
        input_data = {"messages": [Message.text_message("Test", role="user")]}
        
        # Invoke
        invoke_result = await compiled.ainvoke(
            input_data,
            {"thread_id": "test_invoke"},
        )
        
        # Stream
        stream_chunks = []
        async for chunk in compiled.astream(
            input_data,
            {"thread_id": "test_stream"},
        ):
            stream_chunks.append(chunk)
        
        # Both should have completed successfully
        assert len(invoke_result["messages"]) >= 2
        assert len(stream_chunks) > 0
