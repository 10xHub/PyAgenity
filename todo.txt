# TODO:
1. Allow more types of streaming response, it only supported by litellm right now.
2. All stop current execution, From frontend, we can stop the execution of a graph.
3. All Remote Node support, that can be used to run nodes on remote machines.
4. Allow different types of response like image, audio, video etc.





Cancel Current Call, that need to be allowed



# Feedback:
2. Branching support for chat models
3. Remote Node support

